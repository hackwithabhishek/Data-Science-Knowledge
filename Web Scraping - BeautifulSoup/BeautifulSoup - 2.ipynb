{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the data of first 3 movies\n",
    "\n",
    "From this https://www.imdb.com/search/title?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt\n",
    "\n",
    "Find and print the name and genre of the first 3 titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avengers: Infinity War ; Action, Adventure, Sci-Fi\n",
      "Black Panther ; Action, Adventure, Sci-Fi\n",
      "Deadpool 2 ; Action, Adventure, Comedy\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "res = requests.get('https://www.imdb.com/search/title/?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt')\n",
    "data = BeautifulSoup(res.text, 'html.parser')\n",
    "titles = data.find_all(class_ = 'lister-item-content') # it is of type bs4.element.ResultSet\n",
    "genres = data.find_all(class_ = 'genre') # it is of type bs4.element.ResultSet\n",
    "for i in range(3):\n",
    "    gen_i = genres[i].string.strip()\n",
    "    print(titles[i].a.string.strip(),';',gen_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## titles with most votes\n",
    "\n",
    "Link to use https://www.imdb.com/search/title?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt\n",
    "\n",
    "Print the names of movies with highest number of votes from year 2010 to 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception\n",
      "Game of Thrones\n",
      "The Dark Knight Rises\n",
      "The Wolf of Wall Street\n",
      "Interstellar\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "base_url1 = 'https://www.imdb.com/search/title/?release_date='\n",
    "base_url2 = '&sort=num_votes,desc&page=1&ref_=adv_nxt'\n",
    "\n",
    "for i in range(2010,2015):\n",
    "    res = requests.get(base_url1 + str(i) + base_url2)\n",
    "    data = BeautifulSoup(res.text, 'html.parser')\n",
    "    print(data.h3.a.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## title with maximum duration\n",
    "\n",
    "Link to use https://www.imdb.com/search/title?release_date=2018&sort=num_votes,desc&page=1&ref_=adv_nxt\n",
    "\n",
    "Out of the first 250 titles with highest number of votes in 2018,find which title has the maximum duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Haunting of Hill House 572\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "#If we use above link then we need to handle separate case for 1st time. So we use \n",
    "#https://www.imdb.com/search/title/?release_date=2018-01-01,2018-12-31&amp;sort=num_votes,desc&amp;start=1&amp;ref_=adv_nxt\n",
    "\n",
    "url1 = 'https://www.imdb.com/search/title/?release_date=2018-01-01,2018-12-31&amp;sort=num_votes,desc&amp;start='\n",
    "url2 = '&amp;ref_=adv_nxt'\n",
    "\n",
    "max_dur = 0\n",
    "for i in range(5): # in 1 call we get 50 results . So call 5 times bcz we want 250 results\n",
    "    curr_url = url1 + str(i*50+1) + url2\n",
    "    res = requests.get(curr_url)\n",
    "    data = BeautifulSoup(res.text, 'html.parser')\n",
    "    \n",
    "    movies = data.find_all(class_ = 'lister-item-content')\n",
    "    for c in range(50): # bcz 50 results in 1 page\n",
    "        title = movies[c].h3.a.string\n",
    "        duration = movies[c].find(class_='runtime')\n",
    "        if duration is not None: # bcz out of 250 1 movie has no duration given\n",
    "            duration = duration.string.strip()\n",
    "            dur = int(re.search('\\d+',str(duration)).group())\n",
    "            if(dur > max_dur):\n",
    "                max_dur = dur\n",
    "                dur_title = dur\n",
    "                title_name = title\n",
    "        \n",
    "print(title_name, dur_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image with maximum area\n",
    "\n",
    "From this website :https://en.wikipedia.org/wiki/Artificial_intelligence\n",
    "\n",
    "Find and print the src of the <img> tag which occupies the maximum area on the page.\n",
    "\n",
    "#### Note :\n",
    "Ignore images which doesn't have height or width attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//upload.wikimedia.org/wikipedia/commons/thumb/1/13/Joseph_Ayerle_portrait_of_Ornella_Muti_%28detail%29%2C_calculated_by_Artificial_Intelligence_%28AI%29_technology.jpg/220px-Joseph_Ayerle_portrait_of_Ornella_Muti_%28detail%29%2C_calculated_by_Artificial_Intelligence_%28AI%29_technology.jpg\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "res = requests.get('https://en.wikipedia.org/wiki/Artificial_intelligence')\n",
    "data = BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "images = data.find_all('img')\n",
    "max_area = 0\n",
    "for img in images:\n",
    "    w = img.get('width',\"\")\n",
    "    h = img.get('height',\"\")\n",
    "    if w!=\"\" and h!=\"\":\n",
    "        area = int(w)*int(h)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            src = img.get('src')\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quotes with tag humor\n",
    "\n",
    "Find all the quotes that have the tag as \"humor\" from this website http://quotes.toscrape.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "“A day without sunshine is like, you know, night.”\n",
      "“Anyone who thinks sitting in church can make you a Christian must also think that sitting in a garage can make you a car.”\n",
      "“Beauty is in the eye of the beholder and it may be necessary from time to time to give a stupid or misinformed beholder a black eye.”\n",
      "“All you need is love. But a little chocolate now and then doesn't hurt.”\n",
      "“Remember, we're madly in love, so it's all right to kiss me anytime you feel like it.”\n",
      "“Some people never go crazy. What truly horrible lives they must lead.”\n",
      "“The trouble with having an open mind, of course, is that people will insist on coming along and trying to put things in it.”\n",
      "“Think left and think right and think low and think high. Oh, the thinks you can think up if only you try!”\n",
      "“The reason I talk to myself is because I’m the only one whose answers I accept.”\n",
      "“I am free of all prejudice. I hate everyone equally. ”\n",
      "“A lady's imagination is very rapid; it jumps from admiration to love, from love to matrimony in a moment.”\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "base_url = 'http://quotes.toscrape.com'\n",
    "curr_url = 'http://quotes.toscrape.com/page/1/'\n",
    "while True:\n",
    "    res = requests.get(curr_url)\n",
    "    data = BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "    quotes = data.find_all(class_='quote')\n",
    "    for q in quotes:\n",
    "        tags =  q.find(class_ = 'keywords').get('content') # or tag.find(class_ = 'keywords')['content'] \n",
    "        tag_list = tags.split(',')\n",
    "        if \"humor\" in tag_list:\n",
    "            print(q.find(class_='text').string)\n",
    "    \n",
    "    next_page = data.find(class_='next')\n",
    "    if next_page is None:\n",
    "        break\n",
    "    \n",
    "    curr_url = base_url + next_page.a['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print all authors\n",
    "\n",
    "Find and print the names of all the different authors from all pages of this website http://quotes.toscrape.com/\n",
    "\n",
    "Note : Print the names of all authors line wise sorted in dictionary order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albert Einstein\n",
      "Alexandre Dumas fils\n",
      "Alfred Tennyson\n",
      "Allen Saunders\n",
      "André Gide\n",
      "Ayn Rand\n",
      "Bob Marley\n",
      "C.S. Lewis\n",
      "Charles Bukowski\n",
      "Charles M. Schulz\n",
      "Douglas Adams\n",
      "Dr. Seuss\n",
      "E.E. Cummings\n",
      "Eleanor Roosevelt\n",
      "Elie Wiesel\n",
      "Ernest Hemingway\n",
      "Friedrich Nietzsche\n",
      "Garrison Keillor\n",
      "George Bernard Shaw\n",
      "George Carlin\n",
      "George Eliot\n",
      "George R.R. Martin\n",
      "Harper Lee\n",
      "Haruki Murakami\n",
      "Helen Keller\n",
      "J.D. Salinger\n",
      "J.K. Rowling\n",
      "J.M. Barrie\n",
      "J.R.R. Tolkien\n",
      "James Baldwin\n",
      "Jane Austen\n",
      "Jim Henson\n",
      "Jimi Hendrix\n",
      "John Lennon\n",
      "Jorge Luis Borges\n",
      "Khaled Hosseini\n",
      "Madeleine L'Engle\n",
      "Marilyn Monroe\n",
      "Mark Twain\n",
      "Martin Luther King Jr.\n",
      "Mother Teresa\n",
      "Pablo Neruda\n",
      "Ralph Waldo Emerson\n",
      "Stephenie Meyer\n",
      "Steve Martin\n",
      "Suzanne Collins\n",
      "Terry Pratchett\n",
      "Thomas A. Edison\n",
      "W.C. Fields\n",
      "William Nicholson\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "base_url = 'http://quotes.toscrape.com'\n",
    "curr_url = 'http://quotes.toscrape.com/page/1/'\n",
    "authors = {}\n",
    "authors_list = []\n",
    "while True:\n",
    "    res = requests.get(curr_url)\n",
    "    data = BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "    quotes = data.find_all(class_='quote')\n",
    "    for q in quotes:\n",
    "        author = q.find(class_='author')\n",
    "        if author is not None and authors.get(author.string,0)==0:\n",
    "            authors[author.string] = 1\n",
    "            authors_list.append(author.string)\n",
    "        \n",
    "    next_page = data.find(class_='next')\n",
    "    if next_page is None:\n",
    "        break\n",
    "    \n",
    "    curr_url = base_url + next_page.a['href']\n",
    "\n",
    "authors_list.sort()\n",
    "for author in authors_list:\n",
    "    print(author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Birth Date of authors\n",
    "\n",
    "Find the birth date of authors whose name start with 'J' from this website http://quotes.toscrape.com/\n",
    "\n",
    "Note : Print a dictionary containing the name as key and the birth date as value.The Names of authors should be alphabetically sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "base_url = 'http://quotes.toscrape.com'\n",
    "curr_url = 'http://quotes.toscrape.com/page/1/'\n",
    "authors = {}\n",
    "authors_list = []\n",
    "while True:\n",
    "    res = requests.get(curr_url)\n",
    "    data = BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "    quotes = data.find_all(class_='quote')\n",
    "    for q in quotes:\n",
    "        author = q.find(class_='author')\n",
    "        if author is not None and authors.get(author.string,0)==0 and author.string[0]=='J':\n",
    "            about_auhor = base_url + q.find_all('a')[0]['href'] # 1st link gives detail about author\n",
    "            response = requests.get(about_auhor)\n",
    "            auth_data = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            birth = auth_data.find(class_='author-born-date').string\n",
    "            authors[author.string] = str(birth),\n",
    "            authors_list.append((author.string,birth))\n",
    "        \n",
    "    next_page = data.find(class_='next')\n",
    "    if next_page is None:\n",
    "        break\n",
    "    \n",
    "    curr_url = base_url + next_page.a['href']\n",
    "\n",
    "authors_list.sort(key=lambda x: x[0])\n",
    "print('{',end='')\n",
    "for i in range(len(authors_list)):\n",
    "    if i==len(authors_list)-1 :\n",
    "        print(\"'\"+authors_list[i][0]+\"': '\"+authors_list[i][1],end=\"'\")\n",
    "    else:\n",
    "        print(\"'\"+authors_list[i][0]+\"': '\"+authors_list[i][1],end=\"', \")\n",
    "print('}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
